from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt


# 1. 生成模拟数据
X, y = make_classification(
    n_samples=1000,   # 样本数量
    n_features=20,    # 特征数量
    n_informative=15, # 有效特征数量
    n_redundant=5,    # 冗余特征数量
    n_classes=2,      # 分类数量
    random_state=42
)


# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 2. 初始化 Gradient Boosting Classifier
gbm = GradientBoostingClassifier(
    n_estimators=100,      # 基础学习器的数量
    learning_rate=0.1,     # 学习率
    max_depth=3,           # 每棵树的最大深度
    random_state=42
)


# 3. 训练模型
gbm.fit(X_train, y_train)


# 4. 模型预测
y_pred = gbm.predict(X_test)


# 5. 评估模型性能
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(classification_report(y_test, y_pred))


# 6. 特征重要性可视化
feature_importances = gbm.feature_importances_


plt.figure(figsize=(10, 6))
plt.bar(range(len(feature_importances)), feature_importances, color="skyblue")
plt.title("Feature Importance")
plt.xlabel("Feature Index")
plt.ylabel("Importance")
plt.show()



