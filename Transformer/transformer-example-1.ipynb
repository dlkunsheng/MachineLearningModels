{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8ae430-967e-45b3-a784-06eb6ad2a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout, Embedding, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f25a5ec-de02-44c3-a158-ff9083fc6e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据生成：模拟分类任务的序列数据\n",
    "n_samples = 1000\n",
    "sequence_length = 20\n",
    "vocab_size = 50  # 词汇表大小\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51fc5d0-fe0d-4fd5-b61d-bb6c1b4f5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成序列数据和分类标签\n",
    "X = np.random.randint(0, vocab_size, size=(n_samples, sequence_length))  # 输入序列\n",
    "y = np.random.randint(0, n_classes, size=(n_samples,))  # 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc44bc2-015e-484d-9c2f-cbbc17fb67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc44ec7-8971-4527-bca0-24e4bb7a3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义 Transformer 模型\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),  # 前馈网络\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # 多头注意力\n",
    "        attn_output = self.attention(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)  # 残差连接 + Layer Norm\n",
    "        \n",
    "        # 前馈网络\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)  # 残差连接 + Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ca5271-1d9e-4073-bb51-201b8debcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 构建完整的 Transformer 模型\n",
    "def build_transformer_model(sequence_length, vocab_size, embed_dim, num_heads, ff_dim, num_classes):\n",
    "    inputs = Input(shape=(sequence_length,))\n",
    "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    \n",
    "    # 添加 Transformer Block\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    \n",
    "    # 全局池化 + 分类头\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "340749d2-8c3a-4351-a66e-d0af7a322020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型参数\n",
    "embed_dim = 32  # 嵌入维度\n",
    "num_heads = 2   # 注意力头数量\n",
    "ff_dim = 64     # 前馈网络隐藏层维度\n",
    "num_classes = n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18aaab0-aa83-4edf-a4cb-89df5e16e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_transformer_model(sequence_length, vocab_size, embed_dim, num_heads, ff_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b944555d-bd5a-4a21-b268-ebac8b767a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 编译模型\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3bfdc04-847d-4a07-ad09-f290f4016d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5324 - loss: 0.7059 - val_accuracy: 0.5063 - val_loss: 0.7052\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5135 - loss: 0.6977 - val_accuracy: 0.5375 - val_loss: 0.6928\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5607 - loss: 0.6875 - val_accuracy: 0.5250 - val_loss: 0.6902\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6072 - loss: 0.6772 - val_accuracy: 0.5125 - val_loss: 0.6997\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5762 - loss: 0.6741 - val_accuracy: 0.5125 - val_loss: 0.6957\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5670 - loss: 0.6771 - val_accuracy: 0.5063 - val_loss: 0.6966\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5701 - loss: 0.6726 - val_accuracy: 0.5000 - val_loss: 0.7227\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6048 - loss: 0.6674 - val_accuracy: 0.5063 - val_loss: 0.7365\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5668 - loss: 0.6792 - val_accuracy: 0.4812 - val_loss: 0.7166\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6725 - loss: 0.6247 - val_accuracy: 0.5188 - val_loss: 0.7218\n"
     ]
    }
   ],
   "source": [
    "# 5. 训练模型\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6295b7b-281c-4b1e-a38e-0db6f57fd7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Test Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "# 6. 测试模型\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ca9df-aee7-4e16-af47-4a091512b7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
